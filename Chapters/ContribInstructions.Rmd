

# Instructions for Contributors {#C:Instructions}


## Video Contributors 

Each chapter will have 3-8 sections, roughly corresponding to the book.

**Goal.** The purpose of the video is to provide an interactive experience, where learners can review the main ideas of the book.

**Learning Objectives**

*  Start each section with a set of 3 or 4 learning objectives.
*  For each section, the video will reinforce the learning objectives. It is okay to use the learning objectives from the text. Then, the video will provide exactly the information needed for the learner to complete the interactive exercises.

**Background of Viewers.** You can assume that the viewer will have read the text. However, just as students in your classes, they will probably have forgotten the substance. So, big points need to be reinforced.

**Relationship with Tutorials**

*  As part of the purpose of the video is to provide background for the tutorials, there will need to be close co-ordination between the two.
*  Sometimes a video can provide a complicated analysis of a data set and then the tutorial can ask the learner to go through essentially the same analysis albeit with modifications.
*  Many of the overheads will provide a combination of code and output from the code. Explain this to the viewer in a way that he or she can reproduce it in a related situation.

**Video Overheads**

*  Use whatever system you like (e.g., latex/beamer, Powerpoint) to produce the video overheads in .pdf format.
*  If you are indifferent, try `R markdown` (that uses latex/Beamer), as in the [Chapter 1 Example](https://github.com/OpenActTextDev/LDACourse1/tree/main/Overheads). As this integrates well with our online delivery software (R markdown/Bookdown), this will probably become the standard later on as we develop protocols to replicate our work for other courses.


**Video Production**

*  Everyone does this differently, but one approach is to write out the scripts of what you want to say prior to the recording. [Here](https://github.com/OpenActTextDev/LDACourse1/tree/main/Overheads/LDA1.Chap1.OverheadScripts) are some examples for Chapter 1 of the first course. This makes the first draft much longer but becomes more time efficient for those of us who require multiple drafts to get a good quality video. Think of about 1000 words for an 8 minute video.
*  A bonus of writing the scripts in advance is that they may be useful when we decide how we wish to add close-captioning to the videos (really useful for international audiences).
*  Use whatever recording system that you like. If you do not have experience in this, one easily accessible avenue is to use Zoom's ability to record. This is how the Frees examples in Chapter 1 were done. 


## Tutorial Problem Contributors

For each section, the goal is to have one or two tutorial exercises that will reinforce learning objectives of the section.

**Assignment Text**. Start with a set of background information known as the assignment text. This is relatively brief. For example, Datacamp recommends 540 characters with a target range of 30 to 780 characters.

**Instructions**. Next comes a set of instructions, typically written in a bullet fashion where each bullet corresponds to a part. 

*  The target is for three parts but this may range from 1 to 4
*  For each part, the ideal is 360 characters with a target range of 30 to 480 characters.

**Hints** may also be provided. Again they should be short (about 270 characters) and there may be from 0 to 4 hints per exercise.

**Solution Code**. Provide the `R` code that solves the problem described in the assignment text and instructions.

**Sample Code**. Copy the solution code and remove selected variables and function names that you think users would learn from filling in. Consider a range of 8-12 lines of code but feel free to deviate to accomplish learning objectives.

**Success Messages**. Give one to three lines providing encouragement for users and summarizing what they have learned in this exercise. [Here](https://ewfreesres.github.io/SCT-in-R/pre-submission-correctness-test.html) is a description of what these elements look like when coded in `R`.

For most contributors, it is likely that it will be easiest to work with our **TutorialTemplate.Rmd** that you can get when you download the whole site (in the **References** folder), or directly from [here](https://raw.githubusercontent.com/OpenActTextDev/LDAShortCourseStrategy/main/References/TutorialTemplate.Rmd).


### Datacamp Light

Tutorial problem contributors do not need to get into the online tutorial system. Just simply provide the problem set-up (assignment and instructions) and the `R`-code solutions and sample code, with hints and success messages as added plusses. 

The main thing to understand is that the system takes the `R` code, shoots it to a server someplace that executes the code, and sends results back to the user. Although this is very cool (e.g., `R` need not be installed on the user's machine), an implication is that **not all the packages that we want are installed on this server**. Sadly, *Datacamp* has not upgraded this service in the last 2-3 years, so we have to be careful in the choice of packages we use. [Here](http://documents.datacamp.com/default_r_packages.txt) is a list of packages readily available. If you use a package that you have not seen before in the tutorial, please check it prior to providing `R` code. One exception: for this course, we will use a lot of functions from the `actuar()` package and so intend to make them available individually (by putting the source code on Github). Not too clean but it works.

Moreover, if you would like to learn more, see the following.

**Datacamp Light URLs**. [Datacamp](https://www.datacamp.com/) has created a javascript app called *Datacamp Light* that allows for an interactive learning platform in an html environment. In this general app, you do not need to work in an `R` environment but, since we are doing so, life is easier. See https://github.com/datacamp/datacamp-light.

Tutorial problem contributors can start with the R `tutorial` package that one can install, for example, in `R` markdown. In the package [documentation](https://datacamp.github.io/tutorial/), you can see that one can also code up Python exercises with "tutorial". With `R` markdown, we are producing html output. The tutorial package generates some javascript syntax needed from our problems, so we will not need the general *Datacamp Light* app. However, as we are all interested in learning, it may be that the [source code](https://github.com/datacamp/datacamp-light) will be of interest.

Users ultimately want to see a correct solution. If the learner does not get the correct solution, then the Section \@ref(Sec:SCT) **submission correction tests** provides guidance on correcting the source of the mistakes.

### Data 

Many tutorial problems will involve interesting data. You might start with the data in the [Loss Data Analytics](https://openacttexts.github.io/Loss-Data-Analytics/index.html) book as many students will be familiar with them from their reading.

*  <button download><a href="https://raw.githubusercontent.com/OpenActTextDev/LDAShortCourse1/main/Data/PropertyFundInsample.csv">Download Property Fund Data as a .csv file</a></button> 
*  <button download><a href="https://raw.githubusercontent.com/OpenActTextDev/LDAShortCourse1/main/Data/DerrigResampling.csv">Download Resampling Data as a .csv file</a></button>
*  <button download><a href="https://raw.githubusercontent.com/OpenActTextDev/LDAShortCourse1/main/Data/CLAIMLEVEL.csv">Download Claim level Property Fund Data as a .csv file</a></button> 

(Right click, then "save page as" a text or .csv file)

For other datasets, there are a few in the [Regression Modeling with Actuarial and Financial Applications](https://instruction.bus.wisc.edu/jfrees/jfreesbooks/Regression%20Modeling/BookWebDec2010/data.html) book.

In particular, the `R` package [CASdatasets](http://cas.uqam.ca/) has many good choices; this package is based on the book *Computational Actuarial Science with R*.


## Submission Correction Tests Contributors {#Sec:SCT}

These are fairly specialized part of the tutorial system; so, our strategy is to have one or two volunteers that will focus on this aspect. They provide guidance to users on how to correct commonly occurring mistakes. They are a super helpful part of so-called "intelligent tutoring systems" but may take us awhile to implement properly. 

Like the app *Datacamp Light*, Datacamp has created an app called *testwhat* for providing feedback on the `R` version of *Datacamp Light* (another app called [pythonwhat](https://pythonwhat.readthedocs.io/en/latest/) is for Python code. [Other apps](https://intercom.help/datacamp-teach/en/articles/2348740-submission-correctness-tests-deep-dive) are also available for SQL, Shell, and Spreadsheets.). 

Our users submit their code to Datacamp servers and so there is nothing for us to install.

The Submission Correction Tests (SCTs) provides us an opportunity to give "individualized" feedback to help students learn from their mistakes. The basics of the syntax are available from the [testwhat site]( https://datacamp.github.io/testwhat/). **Go through each of the tabs (Syntax, Glossary, Guides, and so on).** Our main challenge will be to anticipate the main types of mistakes that students might make and provide code to help them along.

Here are some additional sources that may be helpful:

*  We have an overview that was written by a [Wisconsin student](https://ewfreesres.github.io/SCT-in-R/index.html). Given the new version of the [testwhat site]( https://datacamp.github.io/testwhat/), it is not as important now. Still, nice to get a student's perspective.
*  See the examples for the [Regression Modeling Short Course](https://ewfreesres.github.io/RegressModel/index.html). For example, for [Exercise 1.1.1](https://ewfreesres.github.io/RegressModel/regression-and-the-normal-distribution.html#exercise.-fitting-galtons-height-data), take a look at the [sample R code](https://github.com/ewfreesRes/RegressModel/blob/master/Chapters/Chapter1.Rmd) (search on `ex="ExerRegMod1.1.2"`).
*  Alternatively (or in addition), here are articles from *Datacamp* that you might want to check out:
      *  [Overview of SCTs](https://instructor-support.datacamp.com/en/articles/2312002-submission-correctness-tests)
      *  [Deep Dive](https://intercom.help/datacamp-teach/en/articles/2348740-submission-correctness-tests-deep-dive)
      *  [Best Practices](https://intercom.help/datacamp-teach/en/articles/2348777-submission-correctness-tests-best-practices)
      
      
